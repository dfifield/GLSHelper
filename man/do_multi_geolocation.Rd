% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/functions.R
\name{do_multi_geolocation}
\alias{do_multi_geolocation}
\title{Do geolocation for multiple GLS data sets}
\usage{
do_multi_geolocation(folder, cfgfile, shapefolder = NULL, subset = NULL)
}
\arguments{
\item{folder}{[character]\cr Required. The name of a folder which contains
the GLS light data for one or more devices. The light data for each device
must be in a separate sub-folder of \code{folder}. The name of each
sub-folder must match the value given in the \code{tagName} column of
\code{cfgfile}. See \emph{Configuration file format} below.}

\item{cfgfile}{[character]\cr Required. The full pathname of a CSV configuration
file. This file contains one line per GLS data set to
be processed. See \emph{Configuration file format} below.}

\item{shapefolder}{[character]\cr optional. The full pathname to a folder
where shapefiles will be stored (if requested),}

\item{subset}{[character]\cr Optional. A character vector of tag names to
include - this is an easy way to only process a subset of the tags listed
in the configuration file. These names must match the \code{tagName}
column in the configuration file. Tags not listed will be excluded from
analysis, as will listed tags whose \code{include} column is \code{FALSE}
in the configuation file.}
}
\value{
A list with one element for each tag data set processed. The names
of the list elements are taken from the \code{tagName} column of the input
configuration file. Each element of this list is itself a list containing:
\itemize{
\item{posns - [dataframe] the computed positions, with columns:}
\itemize{
\item{\code{tFirst, tSecond, type} - sun rise/set times. See
\code{\link[GeoLight]{twilightCalc} for info.}}
\item{\code{src} - the source of the position, either \code{"Calib"} for
calibration period or \code{"Deployment"} for deployment period.}
\item{\code{lng, lat} - the longitude and latitude.}
\item{\code{smthlng, smthlat} - the smoothed longitude and latitude, if
requested.}
}
\item{\code{elev} - [numeric] the sun elevation angle used in the
calculation of positions.}
\item{\code{light} - [dataframe] the raw light data after applying any
optional date filtering.}
\item{\code{act} - [dataframe] the activity data.}
\item{\code{calib} - [dataframe] the raw light data during calibration.}
\item{\code{cfg} - [dataframe] the config settings used.}
\item{\code{m} - a Leaflet map.}
}
}
\description{
Process multiple GLS logger raw light data sets according to
settings given in a configuration file.
}
\details{
This function
reads the config file specified by \code{cfgfile} - each row
specifies the settings for one dataset to process.  It then
processes each data set according to the configuration options given.

\strong{Configuration file format}

The names, data types, and meanings of the columns in the configuration file
file are documented in the list below in the order they appear in the file.

Example configuration CSV and Excel files are included with this package
and can be found in the folder given by the following commands:

\code{system.file("extdata", "geolocation_settings.csv", package = "GLSHelper")}

\describe{
\item{tagName - character, required}{The name of the tag (eg., \verb{MK3005 050}). The data for
each tag must be stored in a unique sub-folder of the \code{folder} argument and
that sub-folder must match the value in the  \code{tagName} column.}

\item{include - logical, required}{Whether to process this tag's data. This is a convenient
way to exclude/include certain tags.}

\item{lightFile - character, required}{The name of the file containing
the light level data. eg., \code{"MK3005 050_000.lig"}.}

\item{log - logical, required}{Whether the raw light values should be log transformed.
This is common for devices that record the entire range of light intensities
such as the Migrate Technology Integeo series tags.}

\item{lThresh - integer, required}{The light threshold level for dawn/dusk. See
\code{\link[GeoLight]{twilightCalc}} in the \pkg{GeoLight} package
for more info.}

\item{maxLightInt - integer, required}{The duration in minutes over which the tag records the
maximum light interval - typically 10, 5, or 2. This corresponds to the
\code{maxLight} argument to \code{\link[GeoLight]{twilightCalc}}}

\item{doTwilights - logical, required}{Whether to do the twilight annotation process. If \code{TRUE}
\code{\link[TwGeos]{preprocessLight}} is invoked to interactively annotate
twilights (see \url{https://geolocationmanual.vogelwarte.ch/twilight.html}).
Once twilights have been annotated, the are save in \code{tagName twilights.rds} in the
the tag's data folder for future use. If \code{FALSE}, the twilights are read from
the previously saved file.}

\item{removeFallEqui - logical, required}{Whether to remove positions during the fall
equinox.}

\item{fallEquiStart, fallEquiEnd - dates in ISO8601 format (YMD, e.g. 2013-09-07), required}{Start/end
dates of the fall equinox period.}

\item{removeSpringEqui - logical, required}{Whether to remove positions during the
spring equinox.}

\item{springEquiStart, springEquiEnd - dates in ISO8601 format (YMD, e.g. 2013-09-07), required}{Start/end
dates of the spring equinox period.}

\item{doDateFilter - logical, required}{Enable configurable date filter? Only positions
with dates between \code{filterStart} and \code{filterEnd} will be retained in the output.}

\item{filterStart, filterEnd - date in ISO8601 format (YMD, e.g. 2013-09-07),
required if \code{doDateFilter} is \code{TRUE}}{Start/end dates of the period to keep.}

\item{deplStart, deplEnd - date in ISO8601 format (YMD, e.g. 2013-07-13), optional}{Start date
of the deployment on the animal. If provided, locations are only be estimated between
\code{deplStart} and \code{deplEnd}.}

\item{deplLat, deplLong - numeric, optional}{Coordinates of the deployment location.
All geographic coordinates are assumed to reference the WGS84 datum.}

\item{calibStart, calibEnd - dates in ISO8601 format (YMD HM, e.g. 2013-06-28 15:00), required}{
Start/end date/time of the calibration (ie, ground-truthing) period.}

\item{calibLat, calibLong - numeric, required}{Coordinates of the calibration location. All geographic
coordinates are assumed to reference the WGS84 datum.}

\item{elev - numeric, optional}{The sun elevation angle when \code{lThresh} units of light
are recorded. Leave blank (normal case) to have this computed from the
calibration data.}

\item{keepCalibPoints - logical, required}{Retain computed calibration points in position
output? See the \code{Value} section below for help on
distinguishing calibration vs deployment positions in the output.}

\item{calibAsk - logical, required}{Ask the user to confirm each twilight during
the calibration period? This corresponds to the \code{ask} argument to
\code{\link[GeoLight]{twilightCalc}}.}

\item{createShapefile - logical, required}{Should a shapefile of the points be
created. Shapefiles will be created in the folder indicated by the
\code{shapefolder} argument. The values of several parameters are incorporated
into the name of the resulting shapefile. For example, if \code{tagName = "MK3005 050"},
\code{lThresh = 16}, \code{elev = -3.48}, \code{boxcarSmooth = TRUE}, and \code{b_iter = 2}
the shapefiles will be named:
\cr
\verb{MK3005 050_thr_16_elev_-3.48_smooth2}
}

\item{boxcarSmooth - logical, required}{Should a boxcar (ie, sliding window)
smoothing filter be applied to the deployment positions? The smoother
adjusts the coordinates of each point taking into account the current
point's coordinates and those of some number of previous and succeeding
points. The number of points to consider, their weightings, and the
function used to combine them are specified by the \code{b_width},
\code{b_w}, and \code{b_func} options respectively. For example, with
\code{b_width = 5}, \code{b_w = c(1,2,3,2,1)}, and \code{b_func =
      'weighted_mean'} the current position's latitude/longitude is the weighted
mean (in a 1:2:3:2:1 ratio) of the second previous, previous, current,
subsequent, and second subsequent positionâ€™s latitude/longitude.
If \code{boxcarSmooth} is \code{TRUE}, then both the smoothed and unsmoothed
positions and paths will be mapped and returned by \link{do_multi_geolocation}.}

\item{b_iter - integer, required if \code{boxcarSmooth} is \code{TRUE}}{
Boxcar smoothers are often applied iteratively and this value indicates
the number of iterations of the smoother to execute. Typical values are
1 or 2.}

\item{b_func - character, required if \code{boxcarSmooth} is \code{TRUE}}{
The name of the function to apply to the
coordinates in the sliding window. Typically this is 'weighted.mean'
and it is unlikely you will need to change this. However any function
that takes a vector of numbers as its 1st argument, a series of weights,
\code{w}, and a logical \code{na.rm}, and returns a single numeric value will
work.}

\item{b_width - integer, required if \code{boxcarSmooth} is \code{TRUE}}{
The width of the sliding window (or boxcar). This controls
how many preceding and succeeding points influence the coordinates of
the current point. Normally this is an odd number (a warning is printed
if not) so that the same number of preceding and succeeding points
exert influence.}

\item{b_pad - logical, required if \code{boxcarSmooth} is \code{TRUE}}{
Should the first (last) positions in the track
be padded with
enough extra copies of themselves to provide a complete \code{b_width} wide
window when processing the first and last windows, respectively.
For example, without padding, the first full window
(e.g., with \code{b_width = 5}) will be centered on the third position, and likewise
the last full window will be centered on the third-last position. This
will cause the resulting smoothed track to have 4 less points than the
original (two lost at the beginning and two at the end).
This is because each full window-width of points in the original
track is converted to a single point in the output (typically as the
weighted mean of its constituents). When \code{b_pad} is \code{TRUE}, a sufficient
number of copies of the first (last) coordinate are inserted at the
beginning (end) of the track so that the first (last) full window
is centered on the first (last) track position. In this case,  the number
of points in the smoothed track is the same as that in the original.}

\item{b_w - integer, required if \code{boxcarSmooth} is \code{TRUE}}{
A vector of length \code{b_width} giving the relative weights
of each position in the sliding window.}

\item{b_na.rm - logical, required if \code{boxcarSmooth} is \code{TRUE}}{
Passed directly to \code{b_func} (typically,
\code{weighted.mean}) indicating whether \code{NA} values should be stripped from
each window before applying \code{b_func}.\code{NA} values can occur in coordinates
if position estimation fails for some points.}

\item{b_anchor.ends - logical, required if \code{boxcarSmooth} is \code{TRUE}}{
If \code{TRUE} fhe first and last positions in
the track are not modified by the smoother. This is useful, for example,
when the first and
final positions of a track are known to be at a specific location
(e.g., breeding colony).}

\item{doSpeedFilter - logical, required}{Should a maximum-speed
filter be applied. If \code{TRUE}, successive positions requiring, on average,
speeds of more than \code{maxSpeed} km/hour will be considered unrealistic and
be removed. Uses \code{\link[GeoLight]{distanceFilter}} from \pkg{GeoLight}.}

\item{maxSpeed - numeric, required if \code{doSpeedFilter} is \code{TRUE}}{
The maximum realistic animal speed in km/h.}

\item{removeOutliers - logical, required}{Should positional outliers outside a
bounding box given by \verb{minX, maxX, minY, maxY} be removed?}

\item{minX, maxX, minY, maxY - numeric, required if \code{removeOutliers} is \code{TRUE}}{
The min/max longitude and latitudes
respectively of the bounding box for removing outliers. Positions whose
coordinates fall on the bounding box are removed.}

\item{doStatPeriods - logical, required}{Should stationary periods be computed? See
\code{\link[GeoLight]{changeLight}} for more information.}

\item{statXlim, statYlim - numeric, optional}{The longitude and latitude limits for the site map
resulting from calculating stationary periods. See \code{doStatPeriods} and
\code{\link[GeoLight]{siteMap}}.}

\item{createKernel - logical, required}{Should kernel utilization distributions be
computed? if \code{TRUE}, \code{\link[adehabitatHR]{kernelUD}} is used to
compute the kernel surface and \code{\link[adehabitatHR]{getverticesHR}}
is use to produce the requested percentage contours. See also
\verb{pcts, projString, h, grid, unin,} and \code{unout} below.}

\item{createKernelShapefile - logical, required if \code{createKernel} is \code{TRUE}}{
Should shapefile(s) of the contoured
kernel utilization distributions be created. If \code{TRUE}, one shapefile
will be created for each value of \code{pcts}. If \code{boxcarSmooth = TRUE},
the smoothed positions will be used for the kernel otherwise the original
unsmoothed points will be. The values of several parameters are incorporated
into the name of the resulting shapefile. For example,
if \code{tagName = "MK3005 050"},
\code{lThresh = 16}, \code{elev = -3.48}, \code{boxcarSmooth = TRUE}, \code{b_iter = 2} and
\code{pcts = c(50, 95)}, then two shapefiles will be produced with names:
\cr
\verb{MK3005 050_thr_16_elev_-3.48_smooth2_UD_50}, and
\cr
\verb{MK3005 050_thr_16_elev_-3.48_smooth2_UD_95}
}

\item{pcts - integer, required if \code{createKernel} is \code{TRUE}}{Vector of
UD contour percentages to compute (e.g., c(50, 95)).}

\item{projString - character, required if \code{createKernel} is \code{TRUE}}{
Because the kernel surface to be contoured
must be computed based on Cartesian
coordinates, the un-projected geographic coordinates (i.e.
latitude/longitude) must be projected to a 2D coordinate system first.
This parameter gives the PROJ4 string of the coordinate system to use
(e.g., \code{"+proj=merc +datum=WGS84 +units=m +ellps=WGS84"}). If
left blank, then a Lambert conformal conic projection will be chosen with
central meridian at the \code{mean} of the point's longitudes, and standard
parallels at 1/6 and 5/6 of the latitudinal range of the positions.}
\item{h - integer, required if \code{createKernel} is \code{TRUE}}{
The kernel smoothing bandwidth parameter - this is the
\code{h} parameter passed to \code{\link[adehabitatHR]{kernelUD}}. If left
blank, then the \code{href} method is used. Otherwise, this value is
in the same units as the chosen projection, typically meters
(see \code{projString})}

\item{unin, unout - character, required if \code{createKernel} is \code{TRUE}}{
These are the input and output units respectively
for the call to
\code{\link[adehabitatHR]{getverticesHR}} to create the UD contours.
\code{unin} must the same as units of the chosen projection (typically \code{m} for
"meters", see \code{projString}). \code{unout} is typically set to \code{km2} so that
the area of the resulting UD contour is in kilometres squared.}

\item{grid - integer, required if \code{createKernel} is \code{TRUE}}{
The number of grid cells for the computed kernel surface. This
is passed as the \code{grid} argument to \code{\link[adehabitatHR]{kernelUD}}.
A typical value is 500.}

\item{plotMap - logical, required}{Should a Leaflet map be plotted for each tag data
set? Maps can only be plotted in this way when \link{do_multi_geolocation}
is called from an interactive R script. This argument will be ignored when
\code{do_multi_geolocation} is called from a knitted RMD document. To plot maps
in a knitted RMD, capture the object
returned by \code{do_multi_geolocation} and print the maps with auxilliary code
inserted directly into a markdown chunk. See \code{Examples}.}

\item{readActivity - logical, required}{Should the tag activity data be read?}

\item{activityType - character, required if \code{readActivity} is \code{TRUE}}{
Type of activity data file to expect.
Currently only accepts \code{coarse} or \code{fine} corresponding to the
coarse-scale or fine-scale activity data of BAS/BioTrack devices.}
}
}
\section{Author}{
 Dave Fifield
}

\examples{
res <- do_multi_geolocation(folder = here::here("Data/Tag data"),
                            cfgfile = here::here("Data/geolocation_settings.csv"),
                            shapefolder = here::here("GIS/Shapefiles"))

# To extract and display maps in a knitted RMD document, place the
# following code in a code chunk:

\code{# Display maps- note this code is safe to execute both interactively and
# during knitting. tagList wraps the Leaflet maps in the appropriate
# HTML to allow them to appear in a knitted document. This will produce
# a series of maps in the output, each labeled with the name of the tag name.

if (isTRUE(getOption('knitr.in.progress'))) {
  html <- list()
  for (i in 1:length(res)) {
    html <- list(html,
                 h2(paste0(i, "_", names(res)[i])),
                 res[[i]]$map)
  }

  tagList(html)
}}

}
