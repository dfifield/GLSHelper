% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/functions.R
\name{do_multi_geolocation}
\alias{do_multi_geolocation}
\title{Do geolocation for multiple GLS data sets}
\usage{
do_multi_geolocation(folder, cfgfile, shapefolder = NULL, subset = NULL)
}
\arguments{
\item{folder}{[character]\cr Required. The name of a folder which contains
the GLS light data for one or more devices. The light data for each device
must be in a separate sub-folder of \code{folder}. The name of each
sub-folder must match the value given in the \code{tagName} column of
\code{cfgfile}. See \emph{Configuration file format} below.}

\item{cfgfile}{[character]\cr Required. The full pathname of a CSV configuration
file. This file contains one line per GLS data set to
be processed. See \emph{Configuration file format} below.}

\item{shapefolder}{[character]\cr optional. The full pathname to a folder
where shapefiles will be stored (if requested),}

\item{subset}{[character]\cr Optional. A character vector of tag names to
include - this is an easy way to only process a subset of the tags listed
in the configuration file. These names must match the \code{tagName}
column in the configuration file. Tags not listed will be excluded from
analysis, as will listed tags whose \code{include} column is \code{FALSE}
in the configuation file.}
}
\value{
A list with one element for each tag data set processed. The names
of the list elements are taken from the \code{tagName} column of the input
configuration file. Each element of this list is itself a list containing:
\itemize{
\item{posns - [dataframe] the computed positions, with columns:}
\itemize{
\item{\code{tFirst, tSecond, type} - sun rise/set times. See
\code{\link[GeoLight]{twilightCalc} for info.}}
\item{\code{src} - the source of the position, either \code{"Calib"} for
calibration period or \code{"Deployment"} for deployment period.}
\item{\code{lng, lat} - the longitude and latitude.}
\item{\code{smthlng, smthlat} - the smoothed longitude and latitude, if
requested.}
}
\item{\code{elev} - [numeric] the sun elevation angle used in the
calculation of positions.}
\item{\code{light} - [dataframe] the raw light data after applying any
optional date filtering.}
\item{\code{act} - [dataframe] the activity data.}
\item{\code{calib} - [dataframe] the raw light data during calibration.}
\item{\code{cfg} - [dataframe] the config settings used.}
\item{\code{m} - a Leaflet map.}
}
}
\description{
Process multiple GLS logger raw light data sets according to
settings given in a configuration file.
}
\details{
This function
reads the config file specified by \code{cfgfile} - each row
specifies the settings for one dataset to process.  It then
processes each data set according to the configuration options given.

\strong{Configuration file format}

The names, data types, and meanings of the columns in the configuration file
file are documented in the list below.

An example configuration CSV file is included with this package
and can be found at the location given by the following command:

\code{system.file("extdata", "geolocation_settings.csv", package = "GLSHelper")}

Note, if you edit your config file
with \code{Excel} make sure the cell type is set to \code{"General"} for all cells.

\describe{
\item{tagName - character}{The name of the tag (eg., \verb{MK3005 050}). The data for
each tag must be stored in a unique sub-folder of the \code{folder} argument and
be named \code{tagName}.}

\item{include - logical}{Whether to process this tag's data. This is a convenient
way to exclude/include certain tags.}

\item{lightFile - character}{The name of the file containing
the light level data. eg., \code{"MK3005 050_000.lig"},}

\item{lThresh - integer}{The light threshold level for dawn/dusk. See
\code{\link[GeoLight]{twilightCalc}} in the \pkg{GeoLight} package
for more info.}

\item{maxLightInt - integer}{The duration in minutes over which the tag records the
maximum light interval - typically 10, 5, or 2. This corresponds to the
\code{maxLight} argument to \code{\link[GeoLight]{twilightCalc}}}

\item{removeFallEqui - logical}{Whether to remove positions during the fall
equinox.}

\item{fallEquiStart - date in ISO8601 format (YMD, e.g. 2013-09-07)}{Start
date of the fall equinox period.}

\item{fallEquiEnd - date in ISO8601 format (YMD, e.g. 2013-10-14)}{End date
of the fall equinox period.}

\item{removeSpringEqui - logical}{Whether to remove positions during the
spring equinox.}

\item{springEquiStart - date in ISO8601 format (YMD, e.g. 2014-02-21)}{Start date
of the spring equinox period.}

\item{springEquiEnd - date in ISO8601 format (YMD, e.g. 2014-04-07)}{End date
of the spring equinox period.}

\item{doDateFilter - logical}{Enable configurable date filter? Only positions
with dates between \code{filterStart} and \code{filterEnd} will be retained.}

\item{filterStart - date in ISO8601 format (YMD, e.g. 2013-09-07)}{Start date
of the period to keep.}

\item{filterEnd - date in ISO8601 format (YMD, e.g. 2014-06-07)}{End date of the
period to keep.}

\item{deplStart - date in ISO8601 format (YMD, e.g. 2013-07-13)}{Start date
of the deployment on the animal.}

\item{deplStart - date in ISO8601 format (YMD, e.g. 2014-06-07)}{End date
of the deployment on the animal.}

\item{deplLat - numeric}{Latitude of the deployment location. All geographic
coordinates are assumed to reference the WGS84 datum.}

\item{deplLong - numeric}{Longitude of the deployment location. All geographic
coordinates are assumed to reference the WGS84 datum.}

\item{calibStart - date in ISO8601 format (YMD HM, e.g. 2013-06-28 15:00)}{
Start date of the calibration (ie, ground-truthing) period.}

\item{calibEnd - date in ISO8601 format (YMD HM, e.g. 2013-07-07 15:00)}{
End date of the calibration (ie, ground-truthing) period.}

\item{calibLat - numeric}{Latitude of the calibration location. All geographic
coordinates are assumed to reference the WGS84 datum.}

\item{calibLong - numeric}{Longitude of the calibration location. All geographic
coordinates are assumed to reference the WGS84 datum.}

\item{elev - numeric}{The sun elevation angle when \code{lThresh} units of light
are recorded. Leave blank (normal case) to have this computed from the
calibration data.}

\item{keepCalibPoints - logical}{Retain computed calibration points in position
output? See the \code{Value} section below for help on
distinguishing calibration vs deployment positions in the output.}

\item{calibAsk - logical}{Ask the user to confirm each twilight during
the calibration period? This corresponds to the \code{ask} argument to
\code{\link[GeoLight]{twilightCalc}}.}

\item{deplAsk - logical}{Ask the user to confirm each twilight during
the deployment period? This corresponds to the \code{ask} argument to
\code{\link[GeoLight]{twilightCalc}}.}

\item{createShapefile - logical}{Should a shapfile of the points be
created. Shapefiles will be created in the folder indicated by the
\code{shapefolder} argument. The values of several parameters are incorporated
into the name of the resulting shapefile. For example, if \code{tagName = "MK3005 050"},
\code{lThresh = 16}, \code{elev = -3.48}, \code{boxcarSmooth = TRUE}, and \code{b_iter = 2}
the shapefiles will be named:
\cr
\verb{MK3005 050_thr_16_elev_-3.48_smooth2}
}

\item{boxcarSmooth - logical}{Should a boxcar (ie, sliding window)
smoothing filter be applied to the deployment positions? The smoother
adjusts the coordinates of each point taking into account the current
point's coordinates and those of some number of previous and succeeding
points. The number of points to consider, their weightings, and the
function used to combine them are specified by the \code{b_width},
\code{b_w}, and \code{b_func} options respectively. For example, with
\code{b_width = 5}, \code{b_w = c(1,2,3,2,1)}, and \code{b_func =
      'weighted_mean'} the current position's latitude/longitude is the weighted
mean (in a 1:2:3:2:1 ratio) of the second previous, previous, current,
subsequent, and second subsequent positionâ€™s latitude/longitude.
If \code{boxcarSmooth} is \code{TRUE}, then both the smoothed and unsmoothed
positions and paths will be mapped and returned by \link{do_multi_geolocation}.}

\item{b_iter - integer}{
Boxcar smoothers are often applied iteratively and this value indicates
the number of iterations of the smoother to execute. Typical values are
1 or 2.}

\item{b_func - character}{The name of the function to apply to the
coordinates in the sliding window. Typically this is 'weighted.mean'
and it is unlikely you will need to change this. However any function
that takes a vector of numbers as its 1st argument, a series of weights,
\code{w}, and a logical \code{na.rm}, and returns a single numeric value will
work.}

\item{b_width - integer}{The width of the sliding window (or boxcar). This controls
how many preceding and succeeding points influence the coordinates of
the current point. Normally this is an odd number (a warning is printed
if not) so that the same number of preceding and succeeding points
exert influence.}

\item{b_pad - logical}{Should the first (last) positions in the track
be padded with
enough extra copies of themselves to provide a complete \code{b_width} wide
window when processing the first and last windows, respectively.
For example, without padding, the first full window
(with \code{b_width = 5}) will be centered on the third position, and likewise
the last full window will be centered on the third-last position. This
will cause the resulting smoothed track to have 4 less points than the
original (two lost at the beginning and two at the end).
This is because each full window-width of points in the original
track is converted to a single point in the output (typically as the
weighted mean of its constituents). When \code{b_pad} is \code{TRUE}, a sufficient
number of copies of the first (last) coordinate are inserted at the
beginning (end) of the track so that the first (last) full window
is centered on the first (last) track position. In this case,  the number
of points in the smoothed track is the same as that in the original.}

\item{b_w - integer}{A vector of length \code{b_width} giving the relative weights
of each position in the sliding window.}

\item{b_na.rm - logical}{Passed directly to \code{b_func} (typically,
\code{weighted.mean}) indicating whether \code{NA} values should be stripped from
each window before applying \code{b_func}.}

\item{b_anchor.ends - logical}{If \code{TRUE} The first and last positions in
the track are not modified by the smoother. This is useful, for example,
when the first and
final positions of a track are known to be at a specific location
(e.g., breeding colony).}

\item{doSpeedFilter - logical}{Should a maximum-speed
filter be applied. If \code{TRUE}, successive positions requiring, on average,
speeds of more than \code{maxSpeed} km/hour will be considered unrealistic and
be removed. Uses \code{\link[GeoLight]{distanceFilter}} from \pkg{GeoLight}.}

\item{maxSpeed - numeric}{The maximum realistic animal speed in km/h.}

\item{removeOutliers - logical}{Should positional outliers outside a
bounding box given by \verb{minX, maxX, minY, maxY} be removed?}

\item{minX, maxX, minY, maxY - numeric}{The min/max longitude and latitudes
respectively of the bounding box for removing outliers. Positions whose
coordinates fall on the bounding box are removed.}

\item{doStatPeriods - logical}{Should stationary periods be computed? See
\code{\link[GeoLight]{changeLight}} for more information.}

\item{Xlim, Ylim - numeric}{The longitude and latitude limits for the site map
resulting from calculating stationary periods. See \code{doStatPeriods} and
\code{\link[GeoLight]{siteMap}}. }

\item{createKernel - logical}{Should kernel utilization distributions be
computed? if \code{TRUE}, \code{\link[adehabitatHR]{kernelUD}} Is used to
compute the kernel surface and \code{\link[adehabitatHR]{getverticesHR}}
is use to produce the requested percentage contours. See also
\verb{pcts, projString, h, grid, unin,} and \code{unout} below.}

\item{createKernelShapefile - logical}{Should shapefile(s) of the contoured
kernel utilization distributions be created. If \code{TRUE}, one shapefile
will be created for each value of \code{pcts}. If \code{boxcarSmooth = TRUE},
the smoothed positions will be used for the kernel otherwise the original
ones will be. The values of several parameters are incorporated
into the name of the resulting shapefile. For example,
if \code{tagName = "MK3005 050"},
\code{lThresh = 16}, \code{elev = -3.48}, \code{boxcarSmooth = TRUE}, \code{b_iter = 2} and
\code{pcts = c(50, 95)}, then two shapefiles will be produced with names:
\cr
\verb{MK3005 050_thr_16_elev_-3.48_smooth2_UD_50}, and
\cr
\verb{MK3005 050_thr_16_elev_-3.48_smooth2_UD_95}
}

\item{pcts - integer}{Vector of UD contour percentages to compute (e.g
c(50, 95)).}

\item{projString - character}{Because the kernel surface to be contoured
must be computed based on Cartesian
coordinates, the un-projected geographic coordinates (i.e.
latitude/longitude) must be projected to a 2D coordinate system first.
This parameter gives the PROJ4 string of the coordinate system to use
(e.g., \code{"+proj=merc +datum=WGS84 +units=m +ellps=WGS84"}). If
left blank, then a Lambert conformal conic projection will be chosen with
central meridian at the \code{mean} of the track's longitudes, and standard
parallels at 1/6 and 5/6 of the latitudinal range of the track's
positions.}
\item{h - integer}{The kernel smoothing bandwidth parameter - this is the
\code{h} parameter passed to \code{\link[adehabitatHR]{kernelUD}}. If left
blank, then the \code{href} method is used. Otherwise, this value is
in the same units as the chosen projection, typically meters
(see \code{projString})}

\item{unin, unout - character}{These are the input and output units respectively
for the call to
\code{\link[adehabitatHR]{getverticesHR}} to create the UD contours.
\code{unin} must the same as units of the chosen projection (typically \code{m} for
"meters", see \code{projString}). \code{unout} is typically set to \code{km2} so that
the area of the resulting UD contour is in kilometres squared.}

\item{grid - integer}{The number of grid cells for the computed kernel surface. This
is passed as the \code{grid} argument to \code{\link[adehabitatHR]{kernelUD}}.}

\item{plotMap - logical}{Should a Leaflet map be plotted for each tag data
set? Maps can only be plotted in this way when \link{do_multi_geolocation}
is called from
an interactive R script. This argument will be ignored when
\code{do_multi_geolocation} is called from a knitted RMD document. To plot maps
in a knitted RMD, capture the object
returned by \code{do_multi_geolocation} and print the maps with auxilliary code
inserted directly into a chunk. See \code{Examples}.}

\item{readActivity - logical}{Should the tag activity data be read?}

\item{activityType - character}{Type of activity data file to expect.
Currently only accepts \code{coarse} or \code{fine} corresponding to the
coarse-scale or fine-scale activity data of BAS/BioTrack devices.}
}
}
\section{Author}{
 Dave Fifield
}

\examples{
res <- do_multi_geolocation(folder = here::here("Data/Tag data"),
                            cfgfile = here::here("Data/geolocation_settings.csv"),
                            shapefolder = here::here("GIS/Shapefiles"))

# To extract and display maps in a knitted RMD document, place the
# following code in a code chunk:
maps <- purrr::map(res, "map") # Extract the maps from the res object.

# Display - note this code is safe to execute both interactively and
# during knitting. tagList wraps the Leaflet maps in the appropriate
# HTML to allow them to appear in a knitted document.
if (isTRUE(getOption('knitr.in.progress'))) {
  maps \%>\%
   tagList
} else {
  maps
}
}
